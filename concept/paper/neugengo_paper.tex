\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\author{Lennart Braun, Armin Schaare, Theresa Eimer 
		\\ Praktikum parallele Programmierung
		\\ Universität Hamburg
		\\ Betreuer: Julian Kunkel}
\title{Nugengo - \\ Kann unser neuronales Netz besser Go spielen als wir?}
\date{}
\begin{document}

\maketitle

\renewcommand{\contentsname}{Inhalt}
\tableofcontents

\newpage

\section{Die Idee}
%Was es tun soll, wieso wir das machen, eine kurze Einleitung eben

Neuronale Netze wurden in den letzten Jahren immer wieder für verschiedene Problemstellungen benutzt. Es wurde festgestellt, dass sie auch komplizierte Aufgaben lösen können, vorausgesetzt sie werden gut genug trainiert. Go zu spielen ist ein sehr komplexe Aufgabe, die wir unter anderem genau aus diesem Grund ausgewählt haben. Wegen der vielen Zugmöglichkeiten und dem mit 19x19 Punkten sehr großen Spielbrett, gibt es für Go noch keine Computer, die Menschen deutlich übertreffen oder sogar eine perfekte Strategie spielen können. Dieses Ziel wäre natürlich etwas hoch gegriffen, doch mit diesem Projekt wollten wir sehen, ob sich neuronale Netze überhaupt gegenseitig so trainieren können, dass sie bessere Ergebnisse erzielen. Dazu wurden zwei Tools benutzt, das erste ist dafür zuständig die Netze zu erstellen und mit Hilfe von Supervised Learning auf die Regeln von Go zu trainieren. Das zweite Tool lässt die Netze dann gegeneinander antreten und rekombiniert sie mit Hilfe eines genetischen Algorithmus. Die so entstandenen Netze können gespeichert werden und auch gegen einen menschlichen Gegner antreten.

\section{Über Go}
%Kurze Beschreibung der Regeln und unsere Umsetzung
Go ist ein asiatisches Brettspiel, das normalerweise auf Brettern von 19x19 oder 9x9 Schnittpunkten gespielt wird. Es gibt zwei Spieler, einer spielt schwarze, der andere weiße Steine. Nacheinander legt zuerst der schwarze, dann der weiße Spieler, je einen Stein auf einen Schnittpunkt. Ist ein Stein umzingelt, sind also alle seine vier direkt angrenzenden Schnittpunkte von gegnerischen Steinen besetzt, so ist er geschlagen und wird vom Brett genommen. Zusammen mit dem auf die selbe Weiße umzingelten Gebiet am Ende des Spieles, bilden die geschlagenen Steine die Punktzahl der Spieler. Wer mehr Punkte hat gewinnt. Eine Sonderregel ist hier das Ko. Es ist möglich in eine Endlosschleife zu geraten, indem ein Stein immer wieder geschlagen und zurückgeschlagen wird. Damit das nicht passiert, darf in dieser Situation nicht sofort zurückgeschlagen werden, sondern erst einen Zug später um dem Gegner die Möglichkeit zu geben die Lücke zu schließen. 
\\
Um das Spiel etwas zu vereinfachen und schneller Ergebnisse zu sehen, arbeiten wir mit 9x9 Spielbrettern. Außerdem gibt es ein Zuglimit für die Spiele, damit es keine Endlosschleifen gibt, die trotz Ko auftreten können. Ansonsten haben wir uns aber bemüht die Go Regeln möglichst gut umzusetzen, damit die Spielstärke auch realistisch beurteilt werden kann.

\section{Unser Programm}

\subsection{Die einzelnen Bereiche}

\subsubsection{Das neuronale Netz}
%Der Aufbau des Netzes, Funktionsweise von Backpropagtion

Ein neuronales Netz besteht aus Neuronen, ähnlich einem menschlichen Gehirn. Die Neuronen sind in Schichten angeordnet, den Layern des Netzes. Das erste Layer ist dabei das Input Layer, das letzte das Output Layer. Zwischen den Layern gehen Kanten von jedem Neuron des einen zu jedem Neuron des anderen Layers. Diese Kanten haben Gewichte und pro Layer gibt es auch einen Bias, der zum Kantengewicht addiert wird. Ein Signal wird durch das Input Layer aufgenommen, durch die Layer weitergegeben und vom Output Layer wieder ausgegeben. Das Weiterleiten innerhalb des Netzes funktioniert über die Kanten. Der Output eines Neurons ist die Summe aller seiner Eingänge. Durch eine Sigmoidfunktion, hier $\frac{1}{1 + e^{-x}}$, werden diese Summen auf den Wertebereich [-1;1] reduziert und gleichzeitig ermöglicht diese Funktion die spätere Anwendung des Backpropagation Algorithmus, da sie differenzierbar ist. Der fertige Output des Neurons wird dann mit den jeweiligen Kantengewichten multipliziert und an die Neuronen des nächsten Layers weitergeleitet. Vor allem hier ist also sehr viel zu Berechnen. 
\\ 
Der Aufbau der Netze ist variabel, die Anzahl der Layer sowie die Anzahl der Neuronen pro Layer ist frei wählbar. Das Input Layer sollte allerdings für jeden Schnittpunkt des Eingabebrettes ein Neuron haben und das Output Layer entsprechend ein Neuron pro Schnittpunkt plus ein Neuron um Passen anzuzeigen. Die Ausgabe sind die Präferenzen der Netze, der Schnittpunkt mit dem höchsten Wert wird besetzt. 
\\
Damit die Netze zumindest die Regeln von vornherein erlernen, gibt es eine Methode für Supervised Learning, überwachtes Lernen, den Backpropagation Algorithmus. Für ihn muss bekannt sein, was das erwartete Ergebnis ist, weswegen die Netze so nur auf die Go Regeln und nicht auf die Taktik trainiert werden können. Der Algorithmus basiert darauf, dass der tatsächliche Ausgabewert mit dem erwarteten Wert verglichen wird und der so ermittelte Fehler zur Korrektur der Kantengewichte benutzt wird. Um die richtigen Korrekturwerte für die einzelnen Layer zu erhalten, muss die Ableitung der Fehlerfunktion durch die Ableitung des Kantengewichts berechnet werden. Dazu summiert man die Fehlersignale der vorhergehenden Schicht mal dem dazugehörigen Kantengewicht auf und multipliziert es mit der Ausgabe des Neurons. So wird nur der Teil des Fehlers, der tatsächlich von diesem Neuron verursacht wurde, korrigiert. 

\subsubsection{Go}
%Welche Komponenten? Wie spielt es zusammen?
\subsubsection{Der genetische Algorithmus}
%Wie funktioniert er?

Der genetische Algorithmus imitiert die Evolution um die Spielstärke der neuronalen Netze zu verbessern. Entsprechend wird auch Terminologie aus der Biologie übernommen: Population, Genom, Mutation, Generation, Fitness. Eine Generation bezeichnet dabei eine Abfolge von Spielen und die Selektion und Mutation der Population. Die Anzahl dieser Generationen wird anfangs festgelegt.
\\
Jedes Netz hat einen bestimmten Fitnesswert, der der Anzahl der gewonnen Spiele entspricht. Sein Genom bilden alle seine Kantengewichte. Alle gegeneinander spielenden Netze zusammen sind eine Population. Soll diese Population eine Generation voran gebracht werden, wird zunächst ausgewählt, welche Individuen in die nächste Generation übernommen werden. Sie werden zufällig ausgesucht, allerdings ist die Wahrscheinlichkeit ein Netz zu wählen proportional zu seinem Fitnesswert. Ist ein Netz also besonders fit, wird es wahrscheinlicher in der nächsten Generation auftauchen. Danach werden die Netze mutiert, ebenfalls zufällig. Es gibt eine bestimmte Mutationswahrscheinlichkeit, mit deren Hilfe überprüft wird, ob ein bestimmtes Kantengewicht mutiert, also um einen zufälligen Wert verändert werden soll, oder nicht. Für jedes Element des Genoms wird eine Zufallszahl zwischen 0 und 1 erzeugt, ist sie kleiner als die Mutationswahrscheinlichkeit, dann wird mutiert. Ist dieser Schritt abgeschlossen, ist die Population eine Generation fortgeschritten. Jetzt muss für jedes Netz wieder die Fitness durch Spiele gegen andere aktualisiert werden und der Algorithmus fängt wieder von vorne an.

\subsection{Die Tools}
%Welche gibt es? Wie setzt man sie ein? Warum macht das so Sinn?

\subsection{Parallelisierung und Optimierung}
%Wie wurde paralellisiert? Was wurde schneller? Wo wird am meisten Zeit verbraucht?

\section{Die Ergebnisse}
%Funktioniert es? Wie ist der Zeitaufwand? Was heißt das für Go mit neuroonalen Netzen?

\section{Fazit}
%Kurzer Schluss

\end{document}