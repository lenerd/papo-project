\section{Leistungsmessung}

Die Messung der Rechenzeit erfolgt innerhalb des Programms in der Main Loop.
Dadurch wird ausschließlich die Zeit erfasst, in der an dem Ergebnis der
Berechnung gearbeitet wird.  Die Sammlung der aufgezeichneten Statistiken
(z.~B. die Anzahl der Züge) durch kollektive MPI-Operationen zählt damit nicht
zur Rechenzeit.

Für die Bestimmung der Güte der erreichten Parallelisierung wurde das Strong
Scaling untersucht, d.~h. ein Problem mit gleichbleibender Größe wird mit
unterschiedlichen Anzahlen an Prozessen berechnet. Anschließend wurde der
Speedup $S_p$ und die Effizienz  $E_p$ wie folgt berechnet, wobei $p$ die
Anzahl der Prozesse und $t_p$ die mit benötigte Laufzeit ist. $t_{seq}$
entspricht der Laufzeit des sequentiellen Programms.
\begin{equation*}
    S_p = \frac{t_{seq}}{t_p} \qquad\qquad E_p = \frac{S_p}{p}
\end{equation*}

Die Laufzeit ist stark abhängig von zufällig generierten Werten: Zum einen
werden die neuronalen Netzwerke zufällig generiert, zum anderen werden diese im
Verlauf des Trainings zufällig mutiert.  Um vergleichbare Messergebnisse zu
erhalten, wurden Vorkehrungen getroffen.  In jeder Messung wird das Programm
mit den gleichen Netzwerken als Eingabe aufgerufen, zudem wird der
Zufallszahlengenerator auf einen bestimmten Wert initialisiert. So kann bei
einer gleichbleibenden Anzahl an Iterationen sichergestellt werden, dass bei
mehreren Aufrufen jeweils die gleiche Menge an Berechnungen durchgeführt wird.
Listing \ref{lst:batch_ss} zeigt ein entsprechendes Batchskript.

\lstset{ %
    captionpos=b,
    frame=single,
    showspaces=false,
    showstringspaces=false,
    numbers=left,
    commentstyle=\color{Gray},
    %stringstyle=\color{PineGreen},
    otherkeywords=mpirun,
    keywordstyle=\color{blue},
}
\lstinputlisting[%
    float,
    language=bash,
    caption=Batchskript zur Messung des Strong Scaling,
    label=lst:batch_ss,
]{content/code/strong_scaling.batch}

Beim Weak Scaling wird die Last mit den proportional zu der Anzahl an Prozessen
erhöht, so dass pro Prozess eine fixe Menge an Arbeit zu berechnen ist.  Das
Weak Scaling zu bestimmen, würde sich schwierig gestalten. Es gibt mehrere
Parameter, die die Menge der Berechnung bestimmen: Anzahl der Generationen,
Anzahl und Layout der Netze. Durch die verwendeten Zufallszahlen, würde es sehr
schwierig sein, anhand dieser Stellschrauben, die Arbeit um einen bestimmten
Faktor zu verändern. Die Arbeit ist vor Allem abhängig von der Anzahl
berechneter Züge.  Würde man mehr Iterationen berechnen, so kann es sein, dass
in den Spielen dieser zusätzlicher Generationen im Schnitt weniger oder mehr
Züge zu berechnen sind. Auch lässt sich bei geänderter Anzahl oder geändertem
Layout (z.~B. Größe) der Netze nicht sagen, für wie viele Züge, die
hinzugefügten bzw. entfernten oder geänderten Netze verantworlich sind.  Eine
Messreihe zum Weak Scaling würde daher nur bedingt verwendbare Ergebnisse
liefern.
